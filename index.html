<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio Splitter and Uploader</title>
    <style>
        pre {
            text-align: right;
            direction: rtl;
            white-space: pre-wrap;
        }
    </style>
</head>
<body>
    <h1>Audio Splitter and Uploader</h1>
    <input type="file" id="audioFile" accept="audio/*">
    <button onclick="splitAndUpload()">Split and Upload</button>
    <p id="status"></p>
    <div id="transcriptionResult"></div>

    <script>
        const maxSizeBytes = 2 * 1024 * 1024; // 2 MB
        let segmentCounter = 1; // Keep track of segment numbering globally

        async function splitAndUpload() {
            const fileInput = document.getElementById('audioFile');
            const audioFile = fileInput.files[0];
            const statusElement = document.getElementById('status');
            const transcriptionElement = document.getElementById('transcriptionResult');
            transcriptionElement.innerHTML = '';

            if (!audioFile) {
                alert('Please select an audio file.');
                return;
            }

            // Split the file into chunks of maxSizeBytes
            const audioChunks = splitAudioBySize(audioFile);

            let allTranscriptions = '';
            let cumulativeTime = 0;
            for (let i = 0; i < audioChunks.length; i++) {
                statusElement.innerText = `Uploading chunk ${i + 1} of ${audioChunks.length}...`;
                const transcription = await uploadChunk(audioChunks[i], i + 1);
                allTranscriptions += formatTranscription(transcription, cumulativeTime);
                cumulativeTime += getLastSegmentEndTime(transcription); // Update cumulative time with the duration of the current chunk
            }

            statusElement.innerText = 'Upload complete.';
            transcriptionElement.innerHTML = `<h2>Transcription Result:</h2><pre>${allTranscriptions}</pre>`;
        }

        function splitAudioBySize(audioFile) {
            const chunks = [];
            let start = 0;

            while (start < audioFile.size) {
                const end = Math.min(start + maxSizeBytes, audioFile.size);
                const chunk = audioFile.slice(start, end);
                chunks.push(new File([chunk], `chunk_${chunks.length + 1}.${audioFile.name.split('.').pop()}`, { type: audioFile.type }));
                start = end;
            }

            return chunks;
        }

        async function uploadChunk(chunk, chunkNumber) {
            const formData = new FormData();
            formData.append('file', chunk);
            formData.append('model', 'whisper-large-v3-turbo');
            formData.append('response_format', 'verbose_json');
            formData.append('language', 'he');

            try {
                const response = await fetch('https://api.groq.com/openai/v1/audio/transcriptions', {
                    method: 'POST',
                    headers: {
                        'Authorization': 'Bearer YOUR_API_KEY_HERE'
                    },
                    body: formData
                });

                if (!response.ok) {
                    const errorText = await response.text();
                    throw new Error(`Error uploading chunk ${chunkNumber}: ${response.statusText} - ${errorText}`);
                }

                const data = await response.json();
                console.log(`Response for chunk ${chunkNumber}:`, data);
                return data;
            } catch (error) {
                console.error(`Failed to upload chunk ${chunkNumber}:`, error);
                alert(`Failed to upload chunk ${chunkNumber}: ${error.message}`);
                return { segments: [] };
            }
        }

        function formatTranscription(transcriptionData, startTime = 0) {
            const segments = transcriptionData.segments || [];
            let formattedTranscription = '';
            let currentTime = startTime;

            segments.forEach((segment) => {
                formattedTranscription += `${segmentCounter}
${formatTimestamp(currentTime)} --> ${formatTimestamp(currentTime + (segment.end - segment.start))}
${segment.text}

`;
                currentTime += (segment.end - segment.start);
                segmentCounter++; // Increment the global segment counter
            });

            return formattedTranscription;
        }

        function getLastSegmentEndTime(transcriptionData) {
            const segments = transcriptionData.segments || [];
            if (segments.length > 0) {
                return segments[segments.length - 1].end;
            }
            return 0;
        }

        function formatTimestamp(seconds) {
            const date = new Date(seconds * 1000);
            const hours = date.getUTCHours().toString().padStart(2, '0');
            const minutes = date.getUTCMinutes().toString().padStart(2, '0');
            const secs = date.getUTCSeconds().toString().padStart(2, '0');
            const ms = date.getUTCMilliseconds().toString().padStart(3, '0');
            return `${hours}:${minutes}:${secs},${ms}`;
        }
    </script>
</body>
</html>
